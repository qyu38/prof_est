{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "# Specify the actual folder and filenames\n",
    "folder_path = 'C:/Users/qyu38/Code/RNN_prof_est'  # Replace with your actual folder path\n",
    "# X_filename = '/X_standardized.npy'\n",
    "# y_filename = '/y.npy'\n",
    "\n",
    "X_filename = '/X_standardized_north_all_real.npy'\n",
    "y_filename = '/y_north_all_real.npy'\n",
    "\n",
    "X_standardized = np.load(folder_path + X_filename)\n",
    "y = np.load(folder_path + y_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.66563489e-01  0.00000000e+00 -9.76170444e-01 ... -6.20594222e-04\n",
      "   2.90077653e-01  6.11379036e-01]\n",
      " [-1.66563489e-01  0.00000000e+00 -9.76170444e-01 ... -1.65759146e-02\n",
      "   2.90077653e-01  5.16529482e-01]\n",
      " [-1.66563489e-01  0.00000000e+00 -9.76170444e-01 ... -5.45734233e-02\n",
      "   2.90077653e-01  4.42722825e-01]\n",
      " ...\n",
      " [-1.66563489e-01  0.00000000e+00 -9.76170444e-01 ...  4.67492965e-01\n",
      "   3.78872911e-01  3.60072158e-01]\n",
      " [-1.66563489e-01  0.00000000e+00 -9.76170444e-01 ...  2.01828941e-01\n",
      "   3.78872911e-01  8.47436589e-01]\n",
      " [-1.66563489e-01  0.00000000e+00 -9.76170444e-01 ... -9.99449365e-02\n",
      "   3.78872911e-01  5.71808047e-01]]\n"
     ]
    }
   ],
   "source": [
    "sample=X_standardized[1]\n",
    "sample2=X_standardized[-1]\n",
    "print(sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: north_hatch_m1_hatch__short_arm_2022_12_13_21_41_run1_i.txt\n",
      "Processed file: north_hatch_m1_hatch__short_arm_2022_12_13_22_28_run2_i.txt\n",
      "Processed file: north_hatch_m1_hatch__short_arm_2022_12_13_22_58_run3_i.txt\n",
      "Processed file: north_sedan_m1_sedan__short_arm_2023_03_12_14_20_run1_i.txt\n",
      "Processed file: north_sedan_m1_sedan__short_arm_2023_03_12_14_50_run2_i.txt\n",
      "Processed file: north_suv_m1_suv__short_arm_2023_03_28_20_19_run1_i.txt\n",
      "Processed file: north_suv_m1_suv__short_arm_2023_03_28_20_52_run2_i.txt\n",
      "Processed file: north_ute_m1_ute__short_arm_2023_02_24_08_31_run1_i.txt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "directory_path = r'\\\\ad.monash.edu\\home\\User028\\qyu38\\Documents\\Code\\Animation of QC suspension in MatLAB\\qcar_animation_for_wfh\\data_set\\test_data'\n",
    "\n",
    "num_features = 7  # Number of feature columns\n",
    "sequence_length = 200  # Length of the sequence for each input\n",
    "processed_features = []\n",
    "processed_labels = []\n",
    "\n",
    "# Iterate over the files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".txt\"):  # Assuming the files are .txt files\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        # Load the file\n",
    "        df = pd.read_csv(file_path, sep='\\t')  # or whatever your separator is\n",
    "        # breakpoint()\n",
    "        # Process the file\n",
    "        for i in range(len(df) - sequence_length + 1):\n",
    "            feature_sequence = df.iloc[i:i + sequence_length, :num_features]\n",
    "                        # Check if any speed in the sequence is less than 5\n",
    "            if not (feature_sequence['speed'] < 5).any():\n",
    "                label = df.iloc[i, -1]\n",
    "                # breakpoint()\n",
    "                #we might need to add a condition here to wipe out features sequences that have speed being less than 5m/s \n",
    "                processed_features.append(feature_sequence.values)\n",
    "                processed_labels.append(label)\n",
    "        print(f\"Processed file: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(processed_features)\n",
    "y = np.array(processed_labels).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45920, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMNet(\n",
      "  (lstm): LSTM(2, 100, num_layers=4, batch_first=True)\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Tanh()\n",
      "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (2): Tanh()\n",
      "    (3): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (4): Tanh()\n",
      "    (5): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (6): Tanh()\n",
      "    (7): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=2, hidden_size=100, num_layers=4, batch_first=True)\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)  # LSTM output is (output, (h_n, c_n)), we only need the output\n",
    "        x = x[:, -1, :]  # Get the last time step output from LSTM\n",
    "        out = self.fc_layers(x)\n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "model = LSTMNet()\n",
    "\n",
    "# Display the model architecture\n",
    "print(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FNO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
